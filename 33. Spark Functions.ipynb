{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea26175-13ec-4dae-8095-cf08401ce22f",
   "metadata": {},
   "source": [
    "## Spark Functions\n",
    "\n",
    "* While DataFrame APIs work on the DataFrame, At times we might want to apply Functions on column values.\n",
    "\n",
    "* Functions to process column values are available under `org.apache.spark.sql.functions`. These are typically used in `select` or `withColumn` on top of DataFrame.\n",
    "\n",
    "* Some of the important Functions can be broadly categorized into `String` Manipulation, `Date` Manipulation, `Numeric` Functions and `Aggregate` Functions.\n",
    "\n",
    "* String Manipulation Functions :\n",
    "\n",
    "    * Concatenating Strings - `concat`\n",
    "    \n",
    "    * Getting Length - `length`\n",
    "\n",
    "    * Trimming Strings - `trim`,` rtrim`, `ltrim`\n",
    "\n",
    "    * Padding Strings - `lpad`, `rpad`\n",
    "\n",
    "    * Extracting Strings - `split`, `substring`\n",
    "    \n",
    "* Date Manipulation Functions :\n",
    "\n",
    "    * Date Arithmetic - `date_add`, `date_sub`, `datediff`, `add_months`\n",
    "\n",
    "    * Date Extraction - `dayofmonth`, `month`, `year`, `date_format`\n",
    "\n",
    "    * Get beginning period - `trunc`, `date_trunc`\n",
    "\n",
    "* Numeric Functions - `abs`, `greatest`\n",
    "\n",
    "* Aggregate Functions - `sum`, `min`, `max`\n",
    "\n",
    "* There are some special functions such as `col`, `lit` etc.\n",
    "\n",
    "    * `col` is used to convert string to column type. It can also be invoked using **$** after importing `spark.implicits._`\n",
    "\n",
    "    * `lit` is used to convert a literal to column value so that it can be used to generate derived fields by manipulating using literals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1660cd-0cc7-494a-9a71-fbb6d7f5e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.138:4043\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1670445833492)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "employees: List[(Int, String, String, Double, String)] = List((1,Scott,Tiger,1000.0,united states), (2,Henry,Ford,1250.0,India), (3,Nick,Junior,750.0,united KINGDOM), (4,Bill,Gomes,1500.0,AUSTRALIA))\n",
       "employeesDF: org.apache.spark.sql.DataFrame = [employee_id: int, first_name: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val employees = List((1, \"Scott\", \"Tiger\", 1000.0, \"united states\"),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \"India\"),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \"united KINGDOM\"),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \"AUSTRALIA\"))\n",
    "\n",
    "val employeesDF = employees.toDF(\"employee_id\", \n",
    "                                 \"first_name\", \n",
    "                                 \"last_name\", \n",
    "                                 \"salary\", \n",
    "                                 \"nationality\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a780d-6416-4bf8-8c90-d68200c2b03e",
   "metadata": {},
   "source": [
    "#### **concat**\n",
    "\n",
    "* `concat` function is used to concatenate two string columns and give new column as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157d48e-81a5-4454-92d2-35a9736e42b3",
   "metadata": {},
   "source": [
    "* `alias` method is used to give an alias name to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45a9e94a-5f31-46a8-90f1-fc9d757795d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+--------------+\n",
      "|employee_id|full_name  |salary|nationality   |\n",
      "+-----------+-----------+------+--------------+\n",
      "|1          |Scott Tiger|1000.0|united states |\n",
      "|2          |Henry Ford |1250.0|India         |\n",
      "|3          |Nick Junior|750.0 |united KINGDOM|\n",
      "|4          |Bill Gomes |1500.0|AUSTRALIA     |\n",
      "+-----------+-----------+------+--------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, lit, concat}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Project full name by concatenating first name and last name along with other fields excluding first name and last name\n",
    "\n",
    "import org.apache.spark.sql.functions.{col, lit, concat}\n",
    "\n",
    "employeesDF.select(col(\"employee_id\"),\n",
    "                   concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")).alias(\"full_name\"),\n",
    "                   col(\"salary\"),\n",
    "                   col(\"nationality\"))\n",
    "           .show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c8d28-fec9-41c1-82e4-37c8ec8dea5f",
   "metadata": {},
   "source": [
    "#### **withColumn**\n",
    "\n",
    "* `withColumn` function is used to Create a new column after computation over other column/columns. It adds a new column at the end of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379c4d82-2571-4ee8-bc43-5c3a3fe23e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------+-----------+\n",
      "|employee_id|salary|nationality   |full_name  |\n",
      "+-----------+------+--------------+-----------+\n",
      "|1          |1000.0|united states |Scott Tiger|\n",
      "|2          |1250.0|India         |Henry Ford |\n",
      "|3          |750.0 |united KINGDOM|Nick Junior|\n",
      "|4          |1500.0|AUSTRALIA     |Bill Gomes |\n",
      "+-----------+------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Alternate Way using withColumn function\n",
    "\n",
    "employeesDF.withColumn(\"full_name\", concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")))\n",
    "           .drop(\"first_name\", \"last_name\")\n",
    "           .show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a81ba-30aa-4869-b23a-c4631b55be07",
   "metadata": {},
   "source": [
    "#### **$**\n",
    "\n",
    "* `$` is an alternate for `col` function, which is used to make a string as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028a2509-8370-45cf-a86c-07e782f653eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------------+-----------+\n",
      "|employee_id|salary|nationality   |full_name  |\n",
      "+-----------+------+--------------+-----------+\n",
      "|1          |1000.0|united states |Scott Tiger|\n",
      "|2          |1250.0|India         |Henry Ford |\n",
      "|3          |750.0 |united KINGDOM|Nick Junior|\n",
      "|4          |1500.0|AUSTRALIA     |Bill Gomes |\n",
      "+-----------+------+--------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Alternate Way using $ function\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "employeesDF.withColumn(\"full_name\", concat($\"first_name\", lit(\" \"), $\"last_name\"))\n",
    "           .drop(\"first_name\", \"last_name\")\n",
    "           .show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75058def-434c-4b06-85c9-a875bcdb8cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+--------------+\n",
      "|employee_id|full_name  |salary|nationality   |\n",
      "+-----------+-----------+------+--------------+\n",
      "|1          |Scott Tiger|1000.0|united states |\n",
      "|2          |Henry Ford |1250.0|India         |\n",
      "|3          |Nick Junior|750.0 |united KINGDOM|\n",
      "|4          |Bill Gomes |1500.0|AUSTRALIA     |\n",
      "+-----------+-----------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Alternate Way using SQL style selectExpr function\n",
    "\n",
    "employeesDF.selectExpr(\"employee_id\",\n",
    "                       \"concat(first_name, ' ', last_name) AS full_name\",\n",
    "                       \"salary\", \n",
    "                       \"nationality\")\n",
    "           .show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99812ad6-dc89-4fc7-8928-7552f398d928",
   "metadata": {},
   "source": [
    "#### **Show all Functions in Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12d38e0-4df0-4020-a788-36b1fa669503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|function                   |\n",
      "+---------------------------+\n",
      "|!                          |\n",
      "|!=                         |\n",
      "|%                          |\n",
      "|&                          |\n",
      "|*                          |\n",
      "|+                          |\n",
      "|-                          |\n",
      "|/                          |\n",
      "|<                          |\n",
      "|<=                         |\n",
      "|<=>                        |\n",
      "|<>                         |\n",
      "|=                          |\n",
      "|==                         |\n",
      "|>                          |\n",
      "|>=                         |\n",
      "|^                          |\n",
      "|abs                        |\n",
      "|acos                       |\n",
      "|acosh                      |\n",
      "|add_months                 |\n",
      "|aes_decrypt                |\n",
      "|aes_encrypt                |\n",
      "|aggregate                  |\n",
      "|and                        |\n",
      "|any                        |\n",
      "|approx_count_distinct      |\n",
      "|approx_percentile          |\n",
      "|array                      |\n",
      "|array_agg                  |\n",
      "|array_contains             |\n",
      "|array_distinct             |\n",
      "|array_except               |\n",
      "|array_intersect            |\n",
      "|array_join                 |\n",
      "|array_max                  |\n",
      "|array_min                  |\n",
      "|array_position             |\n",
      "|array_remove               |\n",
      "|array_repeat               |\n",
      "|array_size                 |\n",
      "|array_sort                 |\n",
      "|array_union                |\n",
      "|arrays_overlap             |\n",
      "|arrays_zip                 |\n",
      "|ascii                      |\n",
      "|asin                       |\n",
      "|asinh                      |\n",
      "|assert_true                |\n",
      "|atan                       |\n",
      "|atan2                      |\n",
      "|atanh                      |\n",
      "|avg                        |\n",
      "|base64                     |\n",
      "|between                    |\n",
      "|bigint                     |\n",
      "|bin                        |\n",
      "|binary                     |\n",
      "|bit_and                    |\n",
      "|bit_count                  |\n",
      "|bit_get                    |\n",
      "|bit_length                 |\n",
      "|bit_or                     |\n",
      "|bit_xor                    |\n",
      "|bool_and                   |\n",
      "|bool_or                    |\n",
      "|boolean                    |\n",
      "|bround                     |\n",
      "|btrim                      |\n",
      "|cardinality                |\n",
      "|case                       |\n",
      "|cast                       |\n",
      "|cbrt                       |\n",
      "|ceil                       |\n",
      "|ceiling                    |\n",
      "|char                       |\n",
      "|char_length                |\n",
      "|character_length           |\n",
      "|chr                        |\n",
      "|coalesce                   |\n",
      "|collect_list               |\n",
      "|collect_set                |\n",
      "|concat                     |\n",
      "|concat_ws                  |\n",
      "|contains                   |\n",
      "|conv                       |\n",
      "|corr                       |\n",
      "|cos                        |\n",
      "|cosh                       |\n",
      "|cot                        |\n",
      "|count                      |\n",
      "|count_if                   |\n",
      "|count_min_sketch           |\n",
      "|covar_pop                  |\n",
      "|covar_samp                 |\n",
      "|crc32                      |\n",
      "|csc                        |\n",
      "|cume_dist                  |\n",
      "|current_catalog            |\n",
      "|current_database           |\n",
      "|current_date               |\n",
      "|current_timestamp          |\n",
      "|current_timezone           |\n",
      "|current_user               |\n",
      "|date                       |\n",
      "|date_add                   |\n",
      "|date_format                |\n",
      "|date_from_unix_date        |\n",
      "|date_part                  |\n",
      "|date_sub                   |\n",
      "|date_trunc                 |\n",
      "|datediff                   |\n",
      "|day                        |\n",
      "|dayofmonth                 |\n",
      "|dayofweek                  |\n",
      "|dayofyear                  |\n",
      "|decimal                    |\n",
      "|decode                     |\n",
      "|degrees                    |\n",
      "|dense_rank                 |\n",
      "|div                        |\n",
      "|double                     |\n",
      "|e                          |\n",
      "|element_at                 |\n",
      "|elt                        |\n",
      "|encode                     |\n",
      "|endswith                   |\n",
      "|every                      |\n",
      "|exists                     |\n",
      "|exp                        |\n",
      "|explode                    |\n",
      "|explode_outer              |\n",
      "|expm1                      |\n",
      "|extract                    |\n",
      "|factorial                  |\n",
      "|filter                     |\n",
      "|find_in_set                |\n",
      "|first                      |\n",
      "|first_value                |\n",
      "|flatten                    |\n",
      "|float                      |\n",
      "|floor                      |\n",
      "|forall                     |\n",
      "|format_number              |\n",
      "|format_string              |\n",
      "|from_csv                   |\n",
      "|from_json                  |\n",
      "|from_unixtime              |\n",
      "|from_utc_timestamp         |\n",
      "|get_json_object            |\n",
      "|getbit                     |\n",
      "|greatest                   |\n",
      "|grouping                   |\n",
      "|grouping_id                |\n",
      "|hash                       |\n",
      "|hex                        |\n",
      "|histogram_numeric          |\n",
      "|hour                       |\n",
      "|hypot                      |\n",
      "|if                         |\n",
      "|ifnull                     |\n",
      "|ilike                      |\n",
      "|in                         |\n",
      "|initcap                    |\n",
      "|inline                     |\n",
      "|inline_outer               |\n",
      "|input_file_block_length    |\n",
      "|input_file_block_start     |\n",
      "|input_file_name            |\n",
      "|instr                      |\n",
      "|int                        |\n",
      "|isnan                      |\n",
      "|isnotnull                  |\n",
      "|isnull                     |\n",
      "|java_method                |\n",
      "|json_array_length          |\n",
      "|json_object_keys           |\n",
      "|json_tuple                 |\n",
      "|kurtosis                   |\n",
      "|lag                        |\n",
      "|last                       |\n",
      "|last_day                   |\n",
      "|last_value                 |\n",
      "|lcase                      |\n",
      "|lead                       |\n",
      "|least                      |\n",
      "|left                       |\n",
      "|length                     |\n",
      "|levenshtein                |\n",
      "|like                       |\n",
      "|ln                         |\n",
      "|locate                     |\n",
      "|log                        |\n",
      "|log10                      |\n",
      "|log1p                      |\n",
      "|log2                       |\n",
      "|lower                      |\n",
      "|lpad                       |\n",
      "|ltrim                      |\n",
      "|make_date                  |\n",
      "|make_dt_interval           |\n",
      "|make_interval              |\n",
      "|make_timestamp             |\n",
      "|make_ym_interval           |\n",
      "|map                        |\n",
      "|map_concat                 |\n",
      "|map_contains_key           |\n",
      "|map_entries                |\n",
      "|map_filter                 |\n",
      "|map_from_arrays            |\n",
      "|map_from_entries           |\n",
      "|map_keys                   |\n",
      "|map_values                 |\n",
      "|map_zip_with               |\n",
      "|max                        |\n",
      "|max_by                     |\n",
      "|md5                        |\n",
      "|mean                       |\n",
      "|min                        |\n",
      "|min_by                     |\n",
      "|minute                     |\n",
      "|mod                        |\n",
      "|monotonically_increasing_id|\n",
      "|month                      |\n",
      "|months_between             |\n",
      "|named_struct               |\n",
      "|nanvl                      |\n",
      "|negative                   |\n",
      "|next_day                   |\n",
      "|not                        |\n",
      "|now                        |\n",
      "|nth_value                  |\n",
      "|ntile                      |\n",
      "|nullif                     |\n",
      "|nvl                        |\n",
      "|nvl2                       |\n",
      "|octet_length               |\n",
      "|or                         |\n",
      "|overlay                    |\n",
      "|parse_url                  |\n",
      "|percent_rank               |\n",
      "|percentile                 |\n",
      "|percentile_approx          |\n",
      "|pi                         |\n",
      "|pmod                       |\n",
      "|posexplode                 |\n",
      "|posexplode_outer           |\n",
      "|position                   |\n",
      "|positive                   |\n",
      "|pow                        |\n",
      "|power                      |\n",
      "|printf                     |\n",
      "|quarter                    |\n",
      "|radians                    |\n",
      "|raise_error                |\n",
      "|rand                       |\n",
      "|randn                      |\n",
      "|random                     |\n",
      "|range                      |\n",
      "|rank                       |\n",
      "|reflect                    |\n",
      "|regexp                     |\n",
      "|regexp_extract             |\n",
      "|regexp_extract_all         |\n",
      "|regexp_like                |\n",
      "|regexp_replace             |\n",
      "|regr_avgx                  |\n",
      "|regr_avgy                  |\n",
      "|regr_count                 |\n",
      "|regr_r2                    |\n",
      "|repeat                     |\n",
      "|replace                    |\n",
      "|reverse                    |\n",
      "|right                      |\n",
      "|rint                       |\n",
      "|rlike                      |\n",
      "|round                      |\n",
      "|row_number                 |\n",
      "|rpad                       |\n",
      "|rtrim                      |\n",
      "|schema_of_csv              |\n",
      "|schema_of_json             |\n",
      "|sec                        |\n",
      "|second                     |\n",
      "|sentences                  |\n",
      "|sequence                   |\n",
      "|session_window             |\n",
      "|sha                        |\n",
      "|sha1                       |\n",
      "|sha2                       |\n",
      "|shiftleft                  |\n",
      "|shiftright                 |\n",
      "|shiftrightunsigned         |\n",
      "|shuffle                    |\n",
      "|sign                       |\n",
      "|signum                     |\n",
      "|sin                        |\n",
      "|sinh                       |\n",
      "|size                       |\n",
      "|skewness                   |\n",
      "|slice                      |\n",
      "|smallint                   |\n",
      "|some                       |\n",
      "|sort_array                 |\n",
      "|soundex                    |\n",
      "|space                      |\n",
      "|spark_partition_id         |\n",
      "|split                      |\n",
      "|split_part                 |\n",
      "|sqrt                       |\n",
      "|stack                      |\n",
      "|startswith                 |\n",
      "|std                        |\n",
      "|stddev                     |\n",
      "|stddev_pop                 |\n",
      "|stddev_samp                |\n",
      "|str_to_map                 |\n",
      "|string                     |\n",
      "|struct                     |\n",
      "|substr                     |\n",
      "|substring                  |\n",
      "|substring_index            |\n",
      "|sum                        |\n",
      "|tan                        |\n",
      "|tanh                       |\n",
      "|timestamp                  |\n",
      "|timestamp_micros           |\n",
      "|timestamp_millis           |\n",
      "|timestamp_seconds          |\n",
      "|tinyint                    |\n",
      "|to_binary                  |\n",
      "|to_csv                     |\n",
      "|to_date                    |\n",
      "|to_json                    |\n",
      "|to_number                  |\n",
      "|to_timestamp               |\n",
      "|to_unix_timestamp          |\n",
      "|to_utc_timestamp           |\n",
      "|transform                  |\n",
      "|transform_keys             |\n",
      "|transform_values           |\n",
      "|translate                  |\n",
      "|trim                       |\n",
      "|trunc                      |\n",
      "|try_add                    |\n",
      "|try_avg                    |\n",
      "|try_divide                 |\n",
      "|try_element_at             |\n",
      "|try_multiply               |\n",
      "|try_subtract               |\n",
      "|try_sum                    |\n",
      "|try_to_binary              |\n",
      "|try_to_number              |\n",
      "|typeof                     |\n",
      "|ucase                      |\n",
      "|unbase64                   |\n",
      "|unhex                      |\n",
      "|unix_date                  |\n",
      "|unix_micros                |\n",
      "|unix_millis                |\n",
      "|unix_seconds               |\n",
      "|unix_timestamp             |\n",
      "|upper                      |\n",
      "|uuid                       |\n",
      "|var_pop                    |\n",
      "|var_samp                   |\n",
      "|variance                   |\n",
      "|version                    |\n",
      "|weekday                    |\n",
      "|weekofyear                 |\n",
      "|when                       |\n",
      "|width_bucket               |\n",
      "|window                     |\n",
      "|xpath                      |\n",
      "|xpath_boolean              |\n",
      "|xpath_double               |\n",
      "|xpath_float                |\n",
      "|xpath_int                  |\n",
      "|xpath_long                 |\n",
      "|xpath_number               |\n",
      "|xpath_short                |\n",
      "|xpath_string               |\n",
      "|xxhash64                   |\n",
      "|year                       |\n",
      "|zip_with                   |\n",
      "||                          |\n",
      "|||                         |\n",
      "|~                          |\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW functions\").show(400, truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b6bf9-acd7-45aa-a0d4-6dc8dc31e855",
   "metadata": {},
   "source": [
    "#### **Describe a Spark Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ab1023-20f1-4259-b87d-510c0e7c91fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+\n",
      "|function_desc                                                                             |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "|Function: concat                                                                          |\n",
      "|Class: org.apache.spark.sql.catalyst.expressions.Concat                                   |\n",
      "|Usage: concat(col1, col2, ..., colN) - Returns the concatenation of col1, col2, ..., colN.|\n",
      "+------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE FUNCTION concat\").show(truncate=false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
