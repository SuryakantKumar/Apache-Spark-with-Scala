{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5bc45c-3a01-44af-8fb8-692bf88573bb",
   "metadata": {},
   "source": [
    "## Spark Read APIs\n",
    "\n",
    "* `spark` has a bunch of APIs to read data from files of different formats.\n",
    "\n",
    "* All APIs are exposed under `spark.read`\n",
    "\n",
    "    * `text` - To read single column data from text files as well as reading each of the whole text file as one record.\n",
    "    \n",
    "    * `csv`- To read text files with delimiters. Default is a `comma`, but we can use other delimiters as well.\n",
    "    \n",
    "    * `json` - To read data from JSON files\n",
    "    \n",
    "    * `orc` - To read data from ORC files\n",
    "    \n",
    "    * `parquet` - To read data from Parquet files\n",
    "\n",
    "* We can also read data from other file formats by plugging in and by using `spark.read.format` but we will also need to use `load` API to pass the `path` of the file.\n",
    "\n",
    "* We can also pass `option / options` based on the file formats.\n",
    "\n",
    "    * `inferSchema` - To infer the Data Types of the columns based on the data.\n",
    "    \n",
    "    * `header` - To use header to get the column names in case of text files.\n",
    "    \n",
    "    * `schema` - To explicitly specify the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53724f52-f2b1-493c-b4ea-735903f2e87e",
   "metadata": {},
   "source": [
    "## Preview Data & Schema\n",
    "\n",
    "* `show` method can be used to preview the data. It will typically show first `20` records where output is truncated.\n",
    "\n",
    "* We can pass number of records and set `truncate` to `false` while previewing the data.\n",
    "\n",
    "* `printSchema` can be used to get the schema details.\n",
    "\n",
    "* `describe` can be used to get statistics out of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fc4074-abdc-472d-902a-ff3693d85d62",
   "metadata": {},
   "source": [
    "### Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3593a46d-8f7b-40d5-b7fc-242f766af2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.1.138:4043\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1670441216901)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.csv(\"data/retail_db/orders/part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a4ae73-4cd0-4653-ba80-71c73d694446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-----+---------------+\n",
      "|_c0|_c1                  |_c2  |_c3            |\n",
      "+---+---------------------+-----+---------------+\n",
      "|1  |2013-07-25 00:00:00.0|11599|CLOSED         |\n",
      "|2  |2013-07-25 00:00:00.0|256  |PENDING_PAYMENT|\n",
      "|3  |2013-07-25 00:00:00.0|12111|COMPLETE       |\n",
      "|4  |2013-07-25 00:00:00.0|8827 |CLOSED         |\n",
      "|5  |2013-07-25 00:00:00.0|11318|COMPLETE       |\n",
      "|6  |2013-07-25 00:00:00.0|7130 |COMPLETE       |\n",
      "|7  |2013-07-25 00:00:00.0|4530 |COMPLETE       |\n",
      "|8  |2013-07-25 00:00:00.0|2911 |PROCESSING     |\n",
      "|9  |2013-07-25 00:00:00.0|5657 |PENDING_PAYMENT|\n",
      "|10 |2013-07-25 00:00:00.0|5648 |PENDING_PAYMENT|\n",
      "|11 |2013-07-25 00:00:00.0|918  |PAYMENT_REVIEW |\n",
      "|12 |2013-07-25 00:00:00.0|1837 |CLOSED         |\n",
      "|13 |2013-07-25 00:00:00.0|9149 |PENDING_PAYMENT|\n",
      "|14 |2013-07-25 00:00:00.0|9842 |PROCESSING     |\n",
      "|15 |2013-07-25 00:00:00.0|2568 |COMPLETE       |\n",
      "|16 |2013-07-25 00:00:00.0|7276 |PENDING_PAYMENT|\n",
      "|17 |2013-07-25 00:00:00.0|2667 |COMPLETE       |\n",
      "|18 |2013-07-25 00:00:00.0|1205 |CLOSED         |\n",
      "|19 |2013-07-25 00:00:00.0|9488 |PENDING_PAYMENT|\n",
      "|20 |2013-07-25 00:00:00.0|9198 |PROCESSING     |\n",
      "+---+---------------------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8158c6b3-3d80-465d-aa04-20ac86cfd9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+-----+---------------+\n",
      "|_c0|_c1                  |_c2  |_c3            |\n",
      "+---+---------------------+-----+---------------+\n",
      "|1  |2013-07-25 00:00:00.0|11599|CLOSED         |\n",
      "|2  |2013-07-25 00:00:00.0|256  |PENDING_PAYMENT|\n",
      "|3  |2013-07-25 00:00:00.0|12111|COMPLETE       |\n",
      "|4  |2013-07-25 00:00:00.0|8827 |CLOSED         |\n",
      "|5  |2013-07-25 00:00:00.0|11318|COMPLETE       |\n",
      "+---+---------------------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2023efbf-3ff6-4d19-abae-e6556d01db45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7b5020-c0ed-4ea1-83af-4a60db49d01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---------------------+-----------------+---------------+\n",
      "|summary|_c0               |_c1                  |_c2              |_c3            |\n",
      "+-------+------------------+---------------------+-----------------+---------------+\n",
      "|count  |68883             |68883                |68883            |68883          |\n",
      "|mean   |34442.0           |null                 |6216.571098819738|null           |\n",
      "|stddev |19884.953633337947|null                 |3586.205241263963|null           |\n",
      "|min    |1                 |2013-07-25 00:00:00.0|1                |CANCELED       |\n",
      "|max    |9999              |2014-07-24 00:00:00.0|9999             |SUSPECTED_FRAUD|\n",
      "+-------+------------------+---------------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.describe().show(truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e07604-1d8a-422d-be05-c9fd7b6094d6",
   "metadata": {},
   "source": [
    "#### **inferSchema**\n",
    "\n",
    "It comes under option while reading CSV file which will give appropriate DataTypes corresponding to each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9889656-6ae0-4166-9d61-18518abc0d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [_c0: int, _c1: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .csv(\"data/retail_db/orders/part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "563ee8df-58f1-432a-92dc-c0aecffab945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+---------------+\n",
      "|_c0|_c1                |_c2  |_c3            |\n",
      "+---+-------------------+-----+---------------+\n",
      "|1  |2013-07-25 00:00:00|11599|CLOSED         |\n",
      "|2  |2013-07-25 00:00:00|256  |PENDING_PAYMENT|\n",
      "|3  |2013-07-25 00:00:00|12111|COMPLETE       |\n",
      "|4  |2013-07-25 00:00:00|8827 |CLOSED         |\n",
      "|5  |2013-07-25 00:00:00|11318|COMPLETE       |\n",
      "+---+-------------------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c85d9f-3ef5-45ef-8a4c-cff2b3f25113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: timestamp (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b39b3a-1b6c-4c02-ad5e-edad39bc9ede",
   "metadata": {},
   "source": [
    "#### **Custom Schema**\n",
    "\n",
    "We can customize the Header column as per our requirements using the method `schema`. We provide schema as a string in format `column_name data_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fd0416c-7bf7-4994-9a52-43035b9d2013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.schema(\"\"\"order_id INT, \n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .csv(\"data/retail_db/orders/part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22831a7-aa9a-4df9-b530-6e549a26368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7e4efad-f68e-43c0-a252-ba76cff33ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33a465-0270-4612-9d2d-77d09c3a17a8",
   "metadata": {},
   "source": [
    "#### **Pass Delimeter**\n",
    "\n",
    "We can pass delimeter as an option while reading CSV file. We can use `sep` for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460906fc-5883-4413-a69f-c0bf925c3415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.schema(\"\"\"order_id INT,\n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .option(\"sep\", \",\")\n",
    "                       .csv(\"data/retail_db/orders/part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d8032e-09a0-49fd-9b56-0b9a3a0abc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c6a3f74-6872-47ea-88fb-177f37ac8640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc6b69-62c0-48aa-b379-1e705c7a2c2c",
   "metadata": {},
   "source": [
    "#### **Load Data with Format**\n",
    "\n",
    "We can use `format` method to `load` any format of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06ab64ea-b652-47d2-9a5e-cc9bb5427636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.schema(\"\"\"order_id INT,\n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .option(\"sep\", \",\")\n",
    "                       .format(\"csv\")\n",
    "                       .load(\"data/retail_db/orders/part-00000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ecd456e-c77f-4d6e-8839-41c71acd69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d4c1dfa-949b-4c73-bd24-75dddcaa0c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f593c6ac-0efe-4794-8f56-150f2ceb2bad",
   "metadata": {},
   "source": [
    "### Read JSON Objects\n",
    "\n",
    "* While reading JSON data from text files, we can directly infer schema from the data as Each JSON object contain both column name and value.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"order_id\" : 1,\n",
    "    \"order_date\" : \"2013-07-25 00:00:00.0\",\n",
    "    \"order_customer_id\" : 12345,\n",
    "    \"order_status\" : \"COMPLETE\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50fa3ca5-eb05-479a-90bb-af835a1179df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_customer_id: bigint, order_date: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.json(\"data/retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06bf5c93-bf65-45a0-9b2b-2af6ccbe3535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+--------+---------------+\n",
      "|order_customer_id|order_date           |order_id|order_status   |\n",
      "+-----------------+---------------------+--------+---------------+\n",
      "|11599            |2013-07-25 00:00:00.0|1       |CLOSED         |\n",
      "|256              |2013-07-25 00:00:00.0|2       |PENDING_PAYMENT|\n",
      "|12111            |2013-07-25 00:00:00.0|3       |COMPLETE       |\n",
      "|8827             |2013-07-25 00:00:00.0|4       |CLOSED         |\n",
      "|11318            |2013-07-25 00:00:00.0|5       |COMPLETE       |\n",
      "+-----------------+---------------------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9f5435c-3c69-4013-bcad-7433a29f31c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052357ee-5659-476a-8b03-c3618434e6eb",
   "metadata": {},
   "source": [
    "#### **Custom Schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f51f225-eab6-4463-a919-f7c5c132afd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.schema(\"\"\"order_id INT,\n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .json(\"data/retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01d9ac78-acd2-4524-9280-d7be35a569ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee41984-14f4-485d-9642-4012cc327bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfc786-15d4-490c-b670-b78d66938fb4",
   "metadata": {},
   "source": [
    "#### **inferSchema**\n",
    "\n",
    "We should not specify `inferSchema` for best practises since Json can directly infer schema.\n",
    "\n",
    "We should mention options very carefully since it doesn't give any error for our mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cd4bbaa-bd1e-47c7-ac70-89a4d6fe8f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.option(\"inferSchema\", \"false\")\n",
    "                       .schema(\"\"\"order_id INT,\n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .json(\"data/retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47ec1937-2e81-41c3-a379-3ff2332794cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc57a292-0fd0-4fb9-8890-e456d6dd407b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f364f195-e576-4155-a636-feba37d8667b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "orders: org.apache.spark.sql.DataFrame = [order_id: int, order_date: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val orders = spark.read.option(\"inferSchema\", \"false\")\n",
    "                       .schema(\"\"\"order_id INT,\n",
    "                                  order_date TIMESTAMP,\n",
    "                                  order_customer_id INT,\n",
    "                                  order_status STRING\"\"\")\n",
    "                       .format(\"json\")\n",
    "                       .load(\"data/retail_db_json/orders/part-r-00000-990f5773-9005-49ba-b670-631286032674\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54dc7b95-3d82-4c50-bf6f-0b8c5163cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|order_date         |order_customer_id|order_status   |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00|11318            |COMPLETE       |\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88babc1-93ff-4b4f-8871-e84dddfc9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
